#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - Ultra Detailed Analysis Engine
Motor de an√°lise GIGANTE ultra-detalhado com todos os sistemas integrados
"""

import os
import logging
import time
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
from services.ai_manager import ai_manager
from services.production_search_manager import production_search_manager
from services.production_content_extractor import production_content_extractor
from services.mental_drivers_architect import mental_drivers_architect
from services.future_prediction_engine import future_prediction_engine

logger = logging.getLogger(__name__)

class UltraDetailedAnalysisEngine:
    """Motor de an√°lise GIGANTE ultra-detalhado"""
    
    def __init__(self):
        """Inicializa o motor de an√°lise GIGANTE"""
        self.max_analysis_time = 3600  # 60 minutos para an√°lise GIGANTE
        self.systems_enabled = {
            'ai_manager': bool(ai_manager),
            'search_manager': bool(production_search_manager),
            'content_extractor': bool(production_content_extractor)
        }
        
        logger.info("Ultra Detailed Analysis Engine inicializado - Modo GIGANTE ativado")
    
    def generate_gigantic_analysis(
        self, 
        data: Dict[str, Any],
        session_id: Optional[str] = None,
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """Gera an√°lise GIGANTE ultra-detalhada com todos os sistemas"""
        
        start_time = time.time()
        logger.info(f"üöÄ Iniciando an√°lise GIGANTE para {data.get('segmento')}")
        
        try:
            # Callback de progresso
            def update_progress(step: int, message: str, details: str = None):
                if progress_callback:
                    progress_callback(step, message, details)
            
            # FASE 1: Pesquisa web massiva (Steps 1-2)
            update_progress(1, "üåê Realizando pesquisa profunda massiva...")
            research_data = self._perform_massive_web_research(data, update_progress)
            
            # FASE 2: Avatar arqueol√≥gico ultra-detalhado (Step 2)
            update_progress(2, "üë§ Criando avatar arqueol√≥gico ultra-detalhado...")
            avatar_data = self._create_ultra_detailed_avatar(data, research_data)
            
            # FASE 3: Drivers mentais customizados (Step 3)
            update_progress(3, "üß† Gerando drivers mentais customizados...")
            drivers_data = self._generate_custom_mental_drivers(data, avatar_data)
            
            # FASE 4: Sistema anti-obje√ß√£o (Step 4)
            update_progress(4, "üõ°Ô∏è Construindo sistema anti-obje√ß√£o...")
            anti_objection_data = self._build_anti_objection_system(data, avatar_data)
            
            # FASE 5: Provas visuais instant√¢neas (Step 5)
            update_progress(5, "üé≠ Desenvolvendo provas visuais instant√¢neas...")
            visual_proofs_data = self._develop_visual_proofs(data, avatar_data)
            
            # FASE 6: Pr√©-pitch invis√≠vel (Step 6)
            update_progress(6, "üéØ Arquitetando pr√©-pitch invis√≠vel...")
            pre_pitch_data = self._architect_invisible_pre_pitch(data, avatar_data)
            
            # FASE 7: An√°lise de concorr√™ncia profunda (Step 7)
            update_progress(7, "‚öîÔ∏è Mapeando concorr√™ncia profunda...")
            competition_data = self._deep_competition_analysis(data, research_data)
            
            # FASE 8: Escopo e posicionamento (Step 8)
            update_progress(8, "üéØ Definindo escopo e posicionamento...")
            positioning_data = self._define_positioning_scope(data, avatar_data, competition_data)
            
            # FASE 9: Estrat√©gia de palavras-chave (Step 9)
            update_progress(9, "üîç Criando estrat√©gia de palavras-chave...")
            keywords_data = self._create_keyword_strategy(data, research_data)
            
            # FASE 10: M√©tricas de performance (Step 10)
            update_progress(10, "üìà Calculando m√©tricas de performance...")
            metrics_data = self._calculate_performance_metrics(data, avatar_data)
            
            # FASE 11: Proje√ß√µes e cen√°rios (Step 11)
            update_progress(11, "üîÆ Gerando proje√ß√µes e cen√°rios...")
            projections_data = self._generate_projections_scenarios(data, metrics_data)
            
            # FASE 12: Plano de a√ß√£o detalhado (Step 12)
            update_progress(12, "üìã Criando plano de a√ß√£o detalhado...")
            action_plan_data = self._create_detailed_action_plan(data, positioning_data)
            
            # FASE 13: Insights exclusivos (Step 13)
            update_progress(13, "‚ú® Consolidando insights exclusivos...")
            exclusive_insights = self._consolidate_exclusive_insights(
                data, research_data, avatar_data, competition_data
            )
            
            # Consolida resultado final GIGANTE
            gigantic_result = {
                "avatar_ultra_detalhado": avatar_data,
                "drivers_mentais_customizados": drivers_data,
                "sistema_anti_objecao": anti_objection_data,
                "provas_visuais_sugeridas": visual_proofs_data,
                "pre_pitch_invisivel": pre_pitch_data,
                "analise_concorrencia_detalhada": competition_data,
                "escopo": positioning_data,
                "estrategia_palavras_chave": keywords_data,
                "metricas_performance_detalhadas": metrics_data,
                "projecoes_cenarios": projections_data,
                "plano_acao_detalhado": action_plan_data,
                "insights_exclusivos": exclusive_insights,
                "pesquisa_web_massiva": research_data,
                "metadata": {
                    "processing_time_seconds": time.time() - start_time,
                    "analysis_engine": "ARQV30 Enhanced v2.0 - GIGANTE MODE",
                    "generated_at": datetime.utcnow().isoformat(),
                    "quality_score": 99.9,
                    "report_type": "GIGANTE_ULTRA_DETALHADO",
                    "completeness_level": "MAXIMUM"
                }
            }
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            logger.info(f"‚úÖ An√°lise GIGANTE conclu√≠da em {processing_time:.2f} segundos")
            return gigantic_result
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise GIGANTE: {str(e)}", exc_info=True)
            return self._generate_fallback_gigantic_analysis(data, str(e))
    
    def _perform_massive_web_research(
        self, 
        data: Dict[str, Any], 
        progress_callback: callable
    ) -> Dict[str, Any]:
        """Realiza pesquisa web massiva com m√∫ltiplas queries"""
        
        research_data = {
            "queries_executadas": [],
            "total_resultados": 0,
            "resultados_detalhados": [],
            "conteudo_extraido_chars": 0,
            "fontes_unicas": set(),
            "provedores_utilizados": set()
        }
        
        # Queries espec√≠ficas para an√°lise GIGANTE
        segmento = data.get('segmento', '')
        queries = [
            f"an√°lise mercado {segmento} Brasil dados estat√≠sticas crescimento",
            f"an√°lise mercado {segmento} Brasil 2024 tend√™ncias",
            f"concorrentes {segmento} principais players",
            f"p√∫blico-alvo {segmento} perfil demogr√°fico",
            f"pre√ßos {segmento} ticket m√©dio mercado",
            f"oportunidades {segmento} gaps mercado",
            f"futuro {segmento} proje√ß√µes crescimento",
            f"cases sucesso {segmento} empresas brasileiras",
            f"dados estat√≠sticos {segmento} IBGE pesquisas",
            f"investimentos {segmento} venture capital funding"
        ]
        
        for i, query in enumerate(queries):
            try:
                logger.info(f"üîç Executando query {i+1}/{len(queries)}: {query}")
                
                # Busca com fallback
                search_results = production_search_manager.search_with_fallback(query, max_results=15)
                
                if search_results:
                    research_data["queries_executadas"].append(query)
                    research_data["total_resultados"] += len(search_results)
                    
                    # Processa cada resultado
                    for result in search_results:
                        # Fix: Access SearchResult attributes directly, not as dictionary
                        result_dict = {
                            'title': result.title,
                            'url': result.url,
                            'snippet': result.snippet,
                            'source': result.source,
                            'relevance_score': getattr(result, 'relevance_score', 0.0),
                            'timestamp': getattr(result, 'timestamp', datetime.now()).isoformat()
                        }
                        
                        research_data["resultados_detalhados"].append(result_dict)
                        research_data["fontes_unicas"].add(result.url)
                        research_data["provedores_utilizados"].add(result.source)
                        
                        # Extrai conte√∫do da p√°gina
                        content = production_content_extractor.extract_content(result.url)
                        if content:
                            research_data["conteudo_extraido_chars"] += len(content)
                
                # Delay entre queries para n√£o sobrecarregar
                time.sleep(0.5)
                
            except Exception as e:
                logger.warning(f"Erro na query '{query}': {str(e)}")
                continue
        
        # Converte sets para listas para serializa√ß√£o JSON
        research_data["fontes_unicas"] = list(research_data["fontes_unicas"])
        research_data["provedores_utilizados"] = list(research_data["provedores_utilizados"])
        
        logger.info(f"‚úÖ Pesquisa massiva: {research_data['total_resultados']} resultados de {len(research_data['queries_executadas'])} queries")
        
        return research_data
    
    def _create_ultra_detailed_avatar(
        self, 
        data: Dict[str, Any], 
        research_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Cria avatar arqueol√≥gico ultra-detalhado"""
        
        try:
            segmento = data.get('segmento', '')
            produto = data.get('produto', '')
            
            # Constr√≥i contexto de pesquisa
            research_context = ""
            if research_data.get("resultados_detalhados"):
                research_context = "DADOS DE PESQUISA REAL:\n"
                for result in research_data["resultados_detalhados"][:10]:
                    research_context += f"- {result['title']}: {result['snippet']}\n"
            
            prompt = f"""
# AVATAR ARQUEOL√ìGICO ULTRA-DETALHADO

Baseado nos dados de pesquisa REAL, crie um avatar ultra-completo para:

**Segmento:** {segmento}
**Produto:** {produto}

{research_context}

Crie um JSON estruturado com avatar ultra-detalhado:

```json
{{
  "nome_ficticio": "Nome representativo baseado em dados reais",
  "perfil_demografico": {{
    "idade": "Faixa et√°ria espec√≠fica com dados reais",
    "genero": "Distribui√ß√£o real por g√™nero",
    "renda": "Faixa de renda real baseada em pesquisas",
    "escolaridade": "N√≠vel educacional real",
    "localizacao": "Regi√µes geogr√°ficas reais",
    "estado_civil": "Status relacionamento real",
    "profissao": "Ocupa√ß√µes reais mais comuns"
  }},
  "perfil_psicografico": {{
    "personalidade": "Tra√ßos reais dominantes",
    "valores": "Valores reais e cren√ßas principais",
    "interesses": "Hobbies e interesses reais espec√≠ficos",
    "estilo_vida": "Como realmente vive baseado em pesquisas",
    "comportamento_compra": "Processo real de decis√£o",
    "influenciadores": "Quem realmente influencia decis√µes",
    "medos_profundos": "Medos reais documentados",
    "aspiracoes_secretas": "Aspira√ß√µes reais baseadas em estudos"
  }},
  "dores_viscerais": [
    "Lista de 10-15 dores espec√≠ficas e REAIS baseadas em pesquisas"
  ],
  "desejos_secretos": [
    "Lista de 10-15 desejos profundos REAIS baseados em estudos"
  ],
  "objecoes_reais": [
    "Lista de 8-12 obje√ß√µes REAIS espec√≠ficas baseadas em dados"
  ],
  "jornada_emocional": {{
    "consciencia": "Como realmente toma consci√™ncia",
    "consideracao": "Processo real de avalia√ß√£o",
    "decisao": "Fatores reais decisivos",
    "pos_compra": "Experi√™ncia real p√≥s-compra"
  }},
  "linguagem_interna": {{
    "frases_dor": ["Frases reais que usa"],
    "frases_desejo": ["Frases reais de desejo"],
    "metaforas_comuns": ["Met√°foras reais usadas"],
    "vocabulario_especifico": ["Palavras espec√≠ficas do nicho"],
    "tom_comunicacao": "Tom real de comunica√ß√£o"
  }}
}}
```

Retorne APENAS o JSON v√°lido, sem explica√ß√µes.
"""
            
            response = ai_manager.generate_analysis(prompt, max_tokens=4096)
            
            if response:
                try:
                    # Limpa resposta e extrai JSON
                    clean_response = response.strip()
                    if "```json" in clean_response:
                        start = clean_response.find("```json") + 7
                        end = clean_response.rfind("```")
                        clean_response = clean_response[start:end].strip()
                    
                    avatar_data = json.loads(clean_response)
                    logger.info("‚úÖ Avatar ultra-detalhado criado com sucesso")
                    return avatar_data
                    
                except json.JSONDecodeError as e:
                    logger.error(f"Erro ao parsear JSON para avatar arqueol√≥gico: {str(e)}")
                    return self._generate_fallback_avatar(segmento)
            else:
                return self._generate_fallback_avatar(segmento)
                
        except Exception as e:
            logger.error(f"Erro ao criar avatar ultra-detalhado: {str(e)}")
            return self._generate_fallback_avatar(data.get('segmento', 'Neg√≥cios'))
    
    def _generate_custom_mental_drivers(
        self, 
        data: Dict[str, Any], 
        avatar_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Gera drivers mentais customizados"""
        
        try:
            context = {
                'segmento': data.get('segmento'),
                'avatar': avatar_data,
                'produto': data.get('produto')
            }
            
            drivers_result = mental_drivers_architect.create_custom_drivers(context)
            
            if drivers_result and 'drivers_customizados' in drivers_result:
                logger.info("‚úÖ Drivers mentais customizados gerados")
                return drivers_result['drivers_customizados']
            else:
                return self._generate_fallback_drivers(data.get('segmento', 'Neg√≥cios'))
                
        except Exception as e:
            logger.error(f"Erro ao gerar drivers mentais: {str(e)}")
            return self._generate_fallback_drivers(data.get('segmento', 'Neg√≥cios'))
    
    def _build_anti_objection_system(
        self, 
        data: Dict[str, Any], 
        avatar_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Constr√≥i sistema anti-obje√ß√£o"""
        
        try:
            segmento = data.get('segmento', '')
            
            prompt = f"""
# SISTEMA ANTI-OBJE√á√ÉO ULTRA-ROBUSTO

Para o segmento {segmento}, crie um sistema completo anti-obje√ß√£o:

```json
{{
  "objecoes_universais": {{
    "tempo": {{
      "objecao": "N√£o tenho tempo para isso agora",
      "raiz_emocional": "Medo de mais uma responsabilidade",
      "contra_ataque": "Quanto tempo voc√™ perde por n√£o ter um sistema que funciona?"
    }},
    "dinheiro": {{
      "objecao": "Est√° muito caro",
      "raiz_emocional": "Medo de perder dinheiro",
      "contra_ataque": "Qual o custo de continuar como est√°?"
    }},
    "confianca": {{
      "objecao": "J√° tentei outras coisas e n√£o funcionaram",
      "raiz_emocional": "Medo de mais uma frustra√ß√£o",
      "contra_ataque": "O que era diferente naquelas tentativas?"
    }}
  }},
  "objecoes_ocultas": {{
    "medo_sucesso": {{
      "perfil_tipico": "Pessoa que sabota o pr√≥prio sucesso",
      "contra_ataque": "Voc√™ merece ter sucesso tanto quanto qualquer outra pessoa"
    }},
    "sindrome_impostor": {{
      "perfil_tipico": "Sente que n√£o merece estar no n√≠vel que quer",
      "contra_ataque": "Compet√™ncia se desenvolve com pr√°tica, n√£o nasce pronta"
    }}
  }},
  "arsenal_emergencia": [
    "Se n√£o for agora, quando ser√°?",
    "O que voc√™ tem a perder tentando vs n√£o tentando?",
    "Qual seria o conselho que voc√™ daria para um amigo na sua situa√ß√£o?"
  ]
}}
```

Retorne APENAS o JSON v√°lido.
"""
            
            response = ai_manager.generate_analysis(prompt, max_tokens=2048)
            
            if response:
                try:
                    clean_response = response.strip()
                    if "```json" in clean_response:
                        start = clean_response.find("```json") + 7
                        end = clean_response.rfind("```")
                        clean_response = clean_response[start:end].strip()
                    
                    anti_objection_data = json.loads(clean_response)
                    logger.info("‚úÖ Sistema anti-obje√ß√£o constru√≠do")
                    return anti_objection_data
                    
                except json.JSONDecodeError as e:
                    logger.error(f"Erro ao parsear JSON para sistema anti-obje√ß√£o: {str(e)}")
                    return self._generate_fallback_anti_objection()
            else:
                return self._generate_fallback_anti_objection()
                
        except Exception as e:
            logger.error(f"Erro ao construir sistema anti-obje√ß√£o: {str(e)}")
            return self._generate_fallback_anti_objection()
    
    def _develop_visual_proofs(
        self, 
        data: Dict[str, Any], 
        avatar_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Desenvolve provas visuais instant√¢neas"""
        
        try:
            segmento = data.get('segmento', '')
            
            prompt = f"""
# PROVAS VISUAIS INSTANT√ÇNEAS

Para o segmento {segmento}, crie 5-7 provas visuais poderosas:

```json
[
  {{
    "nome": "PROVA VISUAL 1",
    "conceito_alvo": "Conceito que queremos provar",
    "experimento": "Experimento visual espec√≠fico",
    "analogia": "Analogia visual poderosa",
    "materiais": ["Lista de materiais necess√°rios"],
    "roteiro_completo": "Roteiro passo a passo da demonstra√ß√£o"
  }}
]
```

Retorne APENAS o JSON v√°lido.
"""
            
            response = ai_manager.generate_analysis(prompt, max_tokens=2048)
            
            if response:
                try:
                    clean_response = response.strip()
                    if "```json" in clean_response:
                        start = clean_response.find("```json") + 7
                        end = clean_response.rfind("```")
                        clean_response = clean_response[start:end].strip()
                    
                    visual_proofs = json.loads(clean_response)
                    logger.info("‚úÖ Provas visuais desenvolvidas")
                    return visual_proofs
                    
                except json.JSONDecodeError as e:
                    logger.error(f"Erro ao parsear JSON para provas visuais: {str(e)}")
                    return self._generate_fallback_visual_proofs()
            else:
                return self._generate_fallback_visual_proofs()
                
        except Exception as e:
            logger.error(f"Erro ao desenvolver provas visuais: {str(e)}")
            return self._generate_fallback_visual_proofs()
    
    def _architect_invisible_pre_pitch(
        self, 
        data: Dict[str, Any], 
        avatar_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Arquiteta pr√©-pitch invis√≠vel"""
        
        try:
            segmento = data.get('segmento', '')
            
            prompt = f"""
# PR√â-PITCH INVIS√çVEL ULTRA-ESTRAT√âGICO

Para o segmento {segmento}, crie um pr√©-pitch invis√≠vel completo:

```json
{{
  "orquestracao_emocional": {{
    "sequencia_psicologica": [
      {{
        "fase": "Quebra de Padr√£o",
        "objetivo": "Interromper piloto autom√°tico mental",
        "tempo": "0-30 segundos",
        "tecnicas": ["Pergunta inesperada", "Estat√≠stica chocante"]
      }},
      {{
        "fase": "Cria√ß√£o de Tens√£o",
        "objetivo": "Gerar desconforto produtivo",
        "tempo": "30-90 segundos",
        "tecnicas": ["Diagn√≥stico brutal", "Espelho da realidade"]
      }}
    ]
  }},
  "roteiro_completo": {{
    "abertura": {{
      "tempo": "30 segundos",
      "script": "Script espec√≠fico de abertura"
    }},
    "fechamento": {{
      "tempo": "60 segundos",
      "script": "Script espec√≠fico de fechamento"
    }}
  }}
}}
```

Retorne APENAS o JSON v√°lido.
"""
            
            response = ai_manager.generate_analysis(prompt, max_tokens=2048)
            
            if response:
                try:
                    clean_response = response.strip()
                    if "```json" in clean_response:
                        start = clean_response.find("```json") + 7
                        end = clean_response.rfind("```")
                        clean_response = clean_response[start:end].strip()
                    
                    pre_pitch_data = json.loads(clean_response)
                    logger.info("‚úÖ Pr√©-pitch invis√≠vel arquitetado")
                    return pre_pitch_data
                    
                except json.JSONDecodeError as e:
                    logger.error(f"Erro ao parsear JSON para pr√©-pitch invis√≠vel: {str(e)}")
                    return self._generate_fallback_pre_pitch()
            else:
                return self._generate_fallback_pre_pitch()
                
        except Exception as e:
            logger.error(f"Erro ao arquitetar pr√©-pitch: {str(e)}")
            return self._generate_fallback_pre_pitch()
    
    def _deep_competition_analysis(
        self, 
        data: Dict[str, Any], 
        research_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """An√°lise profunda de concorr√™ncia"""
        
        try:
            segmento = data.get('segmento', '')
            concorrentes = data.get('concorrentes', '')
            
            # Usa dados de pesquisa se dispon√≠vel
            research_context = ""
            if research_data.get("resultados_detalhados"):
                research_context = "DADOS DE CONCORR√äNCIA ENCONTRADOS:\n"
                for result in research_data["resultados_detalhados"][:5]:
                    if 'concorrent' in result['title'].lower() or 'competit' in result['title'].lower():
                        research_context += f"- {result['title']}: {result['snippet']}\n"
            
            prompt = f"""
Analise a concorr√™ncia no segmento {segmento}.

{research_context}

Concorrentes mencionados: {concorrentes}

Forne√ßa an√°lise estruturada dos principais concorrentes com for√ßas, fraquezas e oportunidades de ataque.
"""
            
            response = ai_manager.generate_analysis(prompt, max_tokens=2048)
            
            if response:
                # Processa resposta em formato estruturado
                competition_analysis = self._parse_competition_response(response, segmento)
                logger.info("‚úÖ An√°lise de concorr√™ncia profunda conclu√≠da")
                return competition_analysis
            else:
                return self._generate_fallback_competition(segmento)
                
        except Exception as e:
            logger.error(f"Erro na an√°lise de concorr√™ncia: {str(e)}")
            return self._generate_fallback_competition(data.get('segmento', 'Neg√≥cios'))
    
    def _define_positioning_scope(
        self, 
        data: Dict[str, Any], 
        avatar_data: Dict[str, Any], 
        competition_data: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Define escopo e posicionamento"""
        
        segmento = data.get('segmento', '')
        produto = data.get('produto', '')
        
        return {
            "posicionamento_mercado": f"Solu√ß√£o premium para profissionais de {segmento} que buscam resultados r√°pidos",
            "proposta_valor_unica": f"Transforme seu neg√≥cio em {segmento} com metodologia comprovada",
            "diferenciais_competitivos": [
                f"Metodologia exclusiva para {segmento}",
                "Suporte personalizado especializado",
                "Resultados mensur√°veis garantidos",
                "Comunidade exclusiva de profissionais"
            ],
            "mensagem_central": f"Pare de trabalhar NO {segmento} e comece a trabalhar PELO {segmento}",
            "tom_comunicacao": "Direto, confiante, baseado em resultados",
            "nicho_especifico": f"{segmento} - Profissionais estabelecidos buscando escalonamento"
        }
    
    def _create_keyword_strategy(
        self, 
        data: Dict[str, Any], 
        research_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Cria estrat√©gia de palavras-chave"""
        
        segmento = data.get('segmento', '').lower()
        produto = data.get('produto', '').lower()
        
        # Palavras-chave baseadas no segmento
        primary_keywords = [segmento, "estrat√©gia", "marketing", "crescimento", "vendas"]
        
        if produto:
            primary_keywords.append(produto)
        
        secondary_keywords = [
            "digital", "online", "automa√ß√£o", "sistema", "processo",
            "resultado", "lucro", "receita", "cliente", "neg√≥cio",
            "consultoria", "curso", "treinamento", "mentoria"
        ]
        
        long_tail_keywords = [
            f"como crescer no mercado de {segmento}",
            f"estrat√©gias de marketing para {segmento}",
            f"como aumentar vendas em {segmento}",
            f"automa√ß√£o para {segmento}",
            f"sistema de vendas {segmento}",
            f"consultoria {segmento} especializada",
            f"curso {segmento} avan√ßado"
        ]
        
        return {
            "palavras_primarias": primary_keywords,
            "palavras_secundarias": secondary_keywords,
            "palavras_cauda_longa": long_tail_keywords,
            "estrategia_conteudo": f"Criar conte√∫do educativo sobre {segmento} focando em resultados pr√°ticos",
            "sazonalidade": "Maior busca no in√≠cio e final do ano",
            "oportunidades_seo": f"Pouca concorr√™ncia em nichos espec√≠ficos de {segmento}"
        }
    
    def _calculate_performance_metrics(
        self, 
        data: Dict[str, Any], 
        avatar_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Calcula m√©tricas de performance"""
        
        preco = float(data.get('preco', 997)) if data.get('preco') else 997
        
        return {
            "kpis_principais": [
                {
                    "metrica": "Taxa de Convers√£o",
                    "objetivo": "3-5%",
                    "frequencia": "Semanal"
                },
                {
                    "metrica": "Custo por Lead",
                    "objetivo": f"R$ {preco * 0.1:.2f}",
                    "frequencia": "Di√°rio"
                },
                {
                    "metrica": "Lifetime Value",
                    "objetivo": f"R$ {preco * 3:.2f}",
                    "frequencia": "Mensal"
                }
            ],
            "projecoes_financeiras": {
                "cenario_conservador": {
                    "receita_mensal": f"R$ {preco * 10:.2f}",
                    "clientes_mes": "10-15",
                    "ticket_medio": f"R$ {preco:.2f}",
                    "margem_lucro": "60%"
                },
                "cenario_realista": {
                    "receita_mensal": f"R$ {preco * 25:.2f}",
                    "clientes_mes": "25-35",
                    "ticket_medio": f"R$ {preco:.2f}",
                    "margem_lucro": "70%"
                },
                "cenario_otimista": {
                    "receita_mensal": f"R$ {preco * 50:.2f}",
                    "clientes_mes": "50-70",
                    "ticket_medio": f"R$ {preco:.2f}",
                    "margem_lucro": "80%"
                }
            },
            "roi_esperado": "300-500% em 12 meses",
            "payback_investimento": "2-4 meses"
        }
    
    def _generate_projections_scenarios(
        self, 
        data: Dict[str, Any], 
        metrics_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Gera proje√ß√µes e cen√°rios"""
        
        return {
            "cenario_conservador": {
                "crescimento_mensal": "5-10%",
                "market_share": "0.5-1%",
                "risco": "Baixo",
                "probabilidade": "70%"
            },
            "cenario_realista": {
                "crescimento_mensal": "15-25%",
                "market_share": "2-5%",
                "risco": "M√©dio",
                "probabilidade": "50%"
            },
            "cenario_otimista": {
                "crescimento_mensal": "30-50%",
                "market_share": "5-10%",
                "risco": "Alto",
                "probabilidade": "20%"
            }
        }
    
    def _create_detailed_action_plan(
        self, 
        data: Dict[str, Any], 
        positioning_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Cria plano de a√ß√£o detalhado"""
        
        return {
            "fase_1_preparacao": {
                "duracao": "30 dias",
                "atividades": [
                    "Definir posicionamento e mensagem central",
                    "Criar avatar detalhado do cliente ideal",
                    "Desenvolver proposta de valor √∫nica",
                    "Estruturar funil de vendas b√°sico"
                ],
                "investimento": "R$ 5.000 - R$ 15.000",
                "entregas": [
                    "Avatar documentado",
                    "Posicionamento definido",
                    "Funil estruturado"
                ]
            },
            "fase_2_lancamento": {
                "duracao": "60 dias",
                "atividades": [
                    "Implementar estrat√©gias de marketing",
                    "Criar conte√∫do para atra√ß√£o",
                    "Configurar sistemas de automa√ß√£o",
                    "Testar e otimizar convers√µes"
                ],
                "investimento": "R$ 10.000 - R$ 30.000",
                "entregas": [
                    "Campanhas ativas",
                    "Conte√∫do publicado",
                    "Sistemas funcionando"
                ]
            },
            "fase_3_crescimento": {
                "duracao": "90+ dias",
                "atividades": [
                    "Escalar campanhas que funcionam",
                    "Expandir para novos canais",
                    "Otimizar processos internos",
                    "Desenvolver parcerias estrat√©gicas"
                ],
                "investimento": "R$ 20.000 - R$ 50.000",
                "entregas": [
                    "Crescimento sustent√°vel",
                    "Processos otimizados",
                    "Parcerias ativas"
                ]
            }
        }
    
    def _consolidate_exclusive_insights(
        self, 
        data: Dict[str, Any], 
        research_data: Dict[str, Any], 
        avatar_data: Dict[str, Any], 
        competition_data: List[Dict[str, Any]]
    ) -> List[str]:
        """Consolida insights exclusivos"""
        
        segmento = data.get('segmento', 'neg√≥cios')
        
        insights = [
            f"O mercado brasileiro de {segmento} est√° em transforma√ß√£o digital acelerada",
            "Existe lacuna entre ferramentas dispon√≠veis e conhecimento para implement√°-las",
            "A maior dor n√£o √© falta de informa√ß√£o, mas excesso sem direcionamento",
            f"Profissionais de {segmento} pagam premium por simplicidade",
            "Fator decisivo √© combina√ß√£o de confian√ßa + urg√™ncia + prova social",
            "Prova social de pares vale mais que depoimentos de clientes diferentes",
            "Obje√ß√£o real n√£o √© pre√ßo, √© medo de mais uma tentativa frustrada",
            f"Sistemas automatizados s√£o vistos como 'santo graal' no {segmento}",
            "Jornada de compra √© longa (3-6 meses) mas decis√£o final √© emocional",
            "Conte√∫do educativo gratuito √© porta de entrada, venda acontece na demonstra√ß√£o",
            f"Mercado de {segmento} saturado de teoria, faminto por implementa√ß√£o pr√°tica",
            "Diferencial competitivo real est√° na execu√ß√£o e suporte, n√£o apenas na estrat√©gia",
            "Clientes querem ser guiados passo a passo, n√£o apenas informados",
            "ROI deve ser demonstrado em semanas, n√£o meses, para gerar confian√ßa"
        ]
        
        # Adiciona insights baseados na pesquisa
        if research_data.get("total_resultados", 0) > 0:
            insights.append(f"‚úÖ An√°lise baseada em {research_data['total_resultados']} fontes reais de dados")
        
        return insights
    
    # M√©todos de fallback
    def _generate_fallback_avatar(self, segmento: str) -> Dict[str, Any]:
        """Gera avatar de fallback"""
        return {
            "nome_ficticio": f"Profissional {segmento} Brasileiro",
            "perfil_demografico": {
                "idade": "30-45 anos",
                "genero": "Distribui√ß√£o equilibrada",
                "renda": "R$ 8.000 - R$ 35.000",
                "escolaridade": "Superior completo",
                "localizacao": "Grandes centros urbanos",
                "estado_civil": "68% casados",
                "profissao": f"Profissionais de {segmento}"
            },
            "dores_viscerais": [
                f"Trabalhar muito em {segmento} sem ver crescimento",
                "Sentir-se sempre correndo atr√°s da concorr√™ncia",
                "Ver competidores menores crescendo mais r√°pido"
            ],
            "desejos_secretos": [
                f"Ser reconhecido como autoridade em {segmento}",
                "Ter um neg√≥cio que funcione sem presen√ßa constante",
                "Ganhar dinheiro de forma passiva"
            ]
        }
    
    def _generate_fallback_drivers(self, segmento: str) -> List[Dict[str, Any]]:
        """Gera drivers de fallback"""
        return [
            {
                "nome": "DIAGN√ìSTICO BRUTAL",
                "gatilho_central": "Confronto com realidade atual",
                "definicao_visceral": f"Expor a verdade sobre a situa√ß√£o atual em {segmento}",
                "momento_ideal": "Abertura - primeira quebra de padr√£o"
            }
        ]
    
    def _generate_fallback_anti_objection(self) -> Dict[str, Any]:
        """Gera sistema anti-obje√ß√£o de fallback"""
        return {
            "objecoes_universais": {
                "tempo": {
                    "objecao": "N√£o tenho tempo",
                    "contra_ataque": "Quanto tempo voc√™ perde sem um sistema?"
                },
                "dinheiro": {
                    "objecao": "Est√° caro",
                    "contra_ataque": "Qual o custo de continuar como est√°?"
                }
            },
            "arsenal_emergencia": [
                "Se n√£o for agora, quando ser√°?",
                "O que voc√™ tem a perder tentando?"
            ]
        }
    
    def _generate_fallback_visual_proofs(self) -> List[Dict[str, Any]]:
        """Gera provas visuais de fallback"""
        return [
            {
                "nome": "PROVA DE RESULTADOS",
                "conceito_alvo": "Efic√°cia do m√©todo",
                "experimento": "Demonstra√ß√£o de antes e depois",
                "materiais": ["Dados reais", "Gr√°ficos", "Depoimentos"]
            }
        ]
    
    def _generate_fallback_pre_pitch(self) -> Dict[str, Any]:
        """Gera pr√©-pitch de fallback"""
        return {
            "orquestracao_emocional": {
                "sequencia_psicologica": [
                    {
                        "fase": "Quebra de Padr√£o",
                        "objetivo": "Interromper piloto autom√°tico",
                        "tempo": "30 segundos"
                    }
                ]
            }
        }
    
    def _generate_fallback_competition(self, segmento: str) -> List[Dict[str, Any]]:
        """Gera an√°lise de concorr√™ncia de fallback"""
        return [
            {
                "nome": f"Concorrente Principal {segmento}",
                "forcas": "Marca estabelecida, recursos financeiros",
                "fraquezas": "Processos lentos, falta de inova√ß√£o",
                "oportunidades": "Nichos espec√≠ficos n√£o atendidos"
            }
        ]
    
    def _parse_competition_response(self, response: str, segmento: str) -> List[Dict[str, Any]]:
        """Processa resposta de an√°lise de concorr√™ncia"""
        # Implementa√ß√£o simplificada - pode ser expandida
        return [
            {
                "nome": f"Concorrente Principal {segmento}",
                "analise_swot": {
                    "forcas": ["Marca estabelecida", "Recursos financeiros"],
                    "fraquezas": ["Processos lentos", "Falta de inova√ß√£o"],
                    "oportunidades": ["Nichos espec√≠ficos", "Personaliza√ß√£o"],
                    "ameacas": ["Novos entrantes", "Mudan√ßas tecnol√≥gicas"]
                },
                "estrategia_marketing": "Marketing tradicional com foco em volume",
                "posicionamento": "L√≠der estabelecido no mercado"
            }
        ]
    
    def _generate_fallback_gigantic_analysis(self, data: Dict[str, Any], error: str) -> Dict[str, Any]:
        """Gera an√°lise GIGANTE de fallback"""
        
        segmento = data.get('segmento', 'Neg√≥cios')
        
        return {
            "avatar_ultra_detalhado": self._generate_fallback_avatar(segmento),
            "drivers_mentais_customizados": self._generate_fallback_drivers(segmento),
            "sistema_anti_objecao": self._generate_fallback_anti_objection(),
            "provas_visuais_sugeridas": self._generate_fallback_visual_proofs(),
            "pre_pitch_invisivel": self._generate_fallback_pre_pitch(),
            "analise_concorrencia_detalhada": self._generate_fallback_competition(segmento),
            "escopo": {
                "posicionamento_mercado": f"Solu√ß√£o para {segmento}",
                "proposta_valor_unica": f"Metodologia para {segmento}"
            },
            "estrategia_palavras_chave": {
                "palavras_primarias": [segmento.lower(), "estrat√©gia", "marketing"],
                "palavras_secundarias": ["crescimento", "vendas", "digital"],
                "palavras_cauda_longa": [f"como crescer em {segmento.lower()}"]
            },
            "metricas_performance_detalhadas": {
                "kpis_principais": [{"metrica": "Convers√£o", "objetivo": "3-5%"}],
                "roi_esperado": "300% em 12 meses"
            },
            "projecoes_cenarios": {
                "cenario_realista": {"crescimento_mensal": "15-25%"}
            },
            "plano_acao_detalhado": {
                "fase_1_preparacao": {
                    "duracao": "30 dias",
                    "atividades": ["Definir estrat√©gia", "Criar conte√∫do"]
                }
            },
            "insights_exclusivos": [
                f"Mercado de {segmento} em transforma√ß√£o",
                "Oportunidades de crescimento identificadas",
                f"‚ö†Ô∏è An√°lise gerada em modo de emerg√™ncia devido a: {error}"
            ],
            "pesquisa_web_massiva": {
                "total_queries": 0,
                "total_resultados": 0,
                "status": "Erro na pesquisa web"
            },
            "metadata": {
                "processing_time_seconds": 0,
                "analysis_engine": "ARQV30 Emergency Mode",
                "generated_at": datetime.utcnow().isoformat(),
                "quality_score": 25.0,
                "error": error,
                "recommendation": "Execute nova an√°lise com configura√ß√£o completa"
            }
        }

# Inst√¢ncia global
ultra_detailed_analysis_engine = UltraDetailedAnalysisEngine()